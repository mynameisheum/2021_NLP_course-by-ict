{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "27-transformer2-실습.ipynb의 사본",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JHkHg6XAXoyK"
      },
      "source": [
        "# Evn*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WkYXFwcBXJDG"
      },
      "source": [
        "# imports\n",
        "import argparse\n",
        "import os\n",
        "import random\n",
        "import shutil\n",
        "import json\n",
        "import zipfile\n",
        "import math\n",
        "import copy\n",
        "import collections\n",
        "import re\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "# import sentencepiece as spm\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras.backend as K\n",
        "\n",
        "from tqdm.notebook import tqdm, trange"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BF-NLGZTGvTR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35aefbd3-89fe-46fa-9256-bf408b56633c"
      },
      "source": [
        "# 환경 설정\n",
        "args = {\n",
        "    # random seed value\n",
        "    \"seed\": 1234\n",
        "}\n",
        "args = argparse.Namespace(**args)\n",
        "\n",
        "print(args)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Namespace(seed=1234)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvjyruUlXtlR"
      },
      "source": [
        "# random seed 설정\n",
        "random.seed(args.seed)\n",
        "np.random.seed(args.seed)\n",
        "tf.random.set_seed(args.seed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BC3fXkhdYcYt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67835bf8-8907-4d05-a82e-bd78ef3602e3"
      },
      "source": [
        "# gpu 사용량 확인\n",
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gfam2ziEnVgU"
      },
      "source": [
        "# Config"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ao2HNCO7nGYR",
        "outputId": "86e07eba-20bf-44b6-b0de-c1a679d66ae9"
      },
      "source": [
        "args.d_model = 8  # d_model: model hidden dim\n",
        "args.n_head = 2  # n_head: multi head attention head number\n",
        "args.d_head = 3  # d_head: multi head attention head dim\n",
        "args.dropout = 0.1  # dropout: dropout rate\n",
        "args.d_ff = 32  # d_ff: feed forward dim\n",
        "args.norm_eps = 1e-9  # norm_eps: layernormal epsilon\n",
        "args.n_layer = 6  # n_layer: layer number\n",
        "args.n_seq = 16  # n_seq: sequence max number\n",
        "args.n_vocab = 16  # n_vocab: vocab count\n",
        "args.i_pad = 0  # i_pad: vocab pad id\n",
        "\n",
        "args"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Namespace(d_ff=32, d_head=3, d_model=8, dropout=0.1, i_pad=0, n_head=2, n_layer=6, n_seq=16, n_vocab=16, norm_eps=1e-09, seed=1234)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "if2wTo_5oOTo"
      },
      "source": [
        "# Inputs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g3vPIEAW4g3Q"
      },
      "source": [
        "# 입력 문장\n",
        "sentences = [\n",
        "    ['나는 오늘 행복해', '나도 기분이 매우 좋아'],\n",
        "    # ['나는 오늘 기분이 좋아', '나도 매우 행복하다'],\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jHEm99xa5IQa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1deabc66-802d-4651-f5b3-e5e03ca1fba4"
      },
      "source": [
        "# 각 문장을 띄어쓰기 단위로 분할\n",
        "words = []\n",
        "for pair in sentences:\n",
        "    for sentence in pair:\n",
        "        words.extend(sentence.split())\n",
        "\n",
        "# 중복 단어 제거\n",
        "words = list(dict.fromkeys(words))\n",
        "\n",
        "# 각 단어별 고유한 번호 부여\n",
        "word_to_id = {'[PAD]': 0, '[UNK]': 1, '[BOS]': 2, '[EOS]': 3}\n",
        "for word in words:\n",
        "    word_to_id[word] = len(word_to_id)\n",
        "\n",
        "# 각 숫자별 단어 부여\n",
        "id_to_word = {_id:word for word, _id in word_to_id.items()}\n",
        "\n",
        "word_to_id, id_to_word"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'[BOS]': 2,\n",
              "  '[EOS]': 3,\n",
              "  '[PAD]': 0,\n",
              "  '[UNK]': 1,\n",
              "  '기분이': 8,\n",
              "  '나는': 4,\n",
              "  '나도': 7,\n",
              "  '매우': 9,\n",
              "  '오늘': 5,\n",
              "  '좋아': 10,\n",
              "  '행복해': 6},\n",
              " {0: '[PAD]',\n",
              "  1: '[UNK]',\n",
              "  2: '[BOS]',\n",
              "  3: '[EOS]',\n",
              "  4: '나는',\n",
              "  5: '오늘',\n",
              "  6: '행복해',\n",
              "  7: '나도',\n",
              "  8: '기분이',\n",
              "  9: '매우',\n",
              "  10: '좋아'})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e1n4AkfH5O1F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91d4c48f-e9eb-4a37-fe51-37c4b2f2ea8e"
      },
      "source": [
        "# train source, target 데이터 생성\n",
        "train_src_ids, tarin_tgt_ids = [], []\n",
        "for pair in sentences:\n",
        "    train_src_ids.append([word_to_id[word] for word in pair[0].split()])\n",
        "    tarin_tgt_ids.append([word_to_id[word] for word in pair[1].split()])\n",
        "train_src_ids, tarin_tgt_ids"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([[4, 5, 6]], [[7, 8, 9, 10]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-CMX8WjcLze",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ecffe6ff-6f91-4ca4-b9e8-0be1aab8e48b"
      },
      "source": [
        "# train enc_inputs, dec_inputs, dec_label 생성\n",
        "train_enc_inputs, train_dec_inputs, train_dec_labels = [], [], []\n",
        "for source_id, target_id in zip(train_src_ids, tarin_tgt_ids):\n",
        "    train_enc_inputs.append(source_id)\n",
        "    train_dec_inputs.append([word_to_id['[BOS]']] + target_id)\n",
        "    train_dec_labels.append(target_id + [word_to_id['[EOS]']])\n",
        "train_enc_inputs, train_dec_inputs, train_dec_labels"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([[4, 5, 6]], [[2, 7, 8, 9, 10]], [[7, 8, 9, 10, 3]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wfVjB9UVcjXQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4d7ea01-f0be-4c6f-8e18-370865dceb33"
      },
      "source": [
        "# 문장의 길이를 모두 동일하게 변경 (최대길이 4)\n",
        "for row in train_enc_inputs:\n",
        "    row += [0] * (4 - len(row))\n",
        "\n",
        "# 문장의 길이를 모두 동일하게 변경 (최대길이 6)\n",
        "for row in train_dec_inputs:\n",
        "    row += [0] * (6 - len(row))\n",
        "\n",
        "# 문장의 길이를 모두 동일하게 변경 (최대길이 6)\n",
        "for row in train_dec_labels:\n",
        "    row += [0] * (6 - len(row))\n",
        "\n",
        "train_enc_inputs, train_dec_inputs, train_dec_labels"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([[4, 5, 6, 0]], [[2, 7, 8, 9, 10, 0]], [[7, 8, 9, 10, 3, 0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oA9OvrUgc6p7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58f4f457-ee94-4986-95ca-d84e23b3775e"
      },
      "source": [
        "# numpy array로 변환\n",
        "train_enc_inputs = np.array(train_enc_inputs)\n",
        "train_dec_inputs = np.array(train_dec_inputs)\n",
        "train_dec_labels = np.array(train_dec_labels)\n",
        "\n",
        "train_enc_inputs, train_dec_inputs, train_dec_labels"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[4, 5, 6, 0]]),\n",
              " array([[ 2,  7,  8,  9, 10,  0]]),\n",
              " array([[ 7,  8,  9, 10,  3,  0]]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4YbA_P8xojCo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c8c2fa1-5a08-4b6f-ed61-e50d3aa8069d"
      },
      "source": [
        "args.n_vocab = len(word_to_id)\n",
        "args.n_seq = 6\n",
        "\n",
        "args"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Namespace(d_ff=32, d_head=3, d_model=8, dropout=0.1, i_pad=0, n_head=2, n_layer=6, n_seq=6, n_vocab=11, norm_eps=1e-09, seed=1234)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aPjz5ab4pQxf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af5647ed-5ee7-4607-f45d-ffd705c8dec8"
      },
      "source": [
        "# embedding with random weight\n",
        "embed_weight = np.random.randint(-90, 100, (args.n_vocab, args.d_model)) / 100\n",
        "\n",
        "embed = tf.keras.layers.Embedding(args.n_vocab, args.d_model, weights=[embed_weight])\n",
        "embed_weight"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.06,  0.15, -0.9 ,  0.31,  0.08,  0.  ,  0.71,  0.24],\n",
              "       [ 0.31, -0.69,  0.29,  0.9 ,  0.26,  0.15,  0.24,  0.79],\n",
              "       [-0.89,  0.52, -0.87, -0.6 ,  0.5 ,  0.19, -0.71, -0.64],\n",
              "       [-0.22,  0.33, -0.26,  0.6 ,  0.94,  0.46,  0.82,  0.62],\n",
              "       [-0.75, -0.18,  0.4 ,  0.54,  0.17,  0.4 , -0.11, -0.44],\n",
              "       [-0.33,  0.93, -0.54, -0.02,  0.71,  0.31,  0.8 , -0.88],\n",
              "       [ 0.19, -0.55, -0.72, -0.14,  0.27, -0.09, -0.82, -0.15],\n",
              "       [-0.75, -0.7 , -0.74, -0.29,  0.23,  0.06,  0.36, -0.33],\n",
              "       [-0.41, -0.28,  0.95,  0.65, -0.03,  0.73,  0.74, -0.06],\n",
              "       [-0.29, -0.62, -0.89, -0.79,  0.55, -0.6 , -0.52,  0.08],\n",
              "       [ 0.63, -0.34,  0.62, -0.78,  0.06, -0.82, -0.43, -0.03]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qmiVm-ZbpWRo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81182714-5011-4eed-9b3e-380cc57d30b0"
      },
      "source": [
        "# encoder hidden\n",
        "hidden_enc = embed(train_enc_inputs)\n",
        "hidden_enc"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 4, 8), dtype=float32, numpy=\n",
              "array([[[-0.75, -0.18,  0.4 ,  0.54,  0.17,  0.4 , -0.11, -0.44],\n",
              "        [-0.33,  0.93, -0.54, -0.02,  0.71,  0.31,  0.8 , -0.88],\n",
              "        [ 0.19, -0.55, -0.72, -0.14,  0.27, -0.09, -0.82, -0.15],\n",
              "        [-0.06,  0.15, -0.9 ,  0.31,  0.08,  0.  ,  0.71,  0.24]]],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gYlr1HUOpdPp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f829bf11-7558-44f3-c609-70df6d5fb894"
      },
      "source": [
        "# decoder hidden\n",
        "hidden_dec = embed(train_dec_inputs)\n",
        "hidden_dec"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 6, 8), dtype=float32, numpy=\n",
              "array([[[-0.89,  0.52, -0.87, -0.6 ,  0.5 ,  0.19, -0.71, -0.64],\n",
              "        [-0.75, -0.7 , -0.74, -0.29,  0.23,  0.06,  0.36, -0.33],\n",
              "        [-0.41, -0.28,  0.95,  0.65, -0.03,  0.73,  0.74, -0.06],\n",
              "        [-0.29, -0.62, -0.89, -0.79,  0.55, -0.6 , -0.52,  0.08],\n",
              "        [ 0.63, -0.34,  0.62, -0.78,  0.06, -0.82, -0.43, -0.03],\n",
              "        [-0.06,  0.15, -0.9 ,  0.31,  0.08,  0.  ,  0.71,  0.24]]],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BHIf3KEV09K3"
      },
      "source": [
        "# Mask"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DMLh4TXbGrHf"
      },
      "source": [
        "## PAD Mask"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ctSRBdAeG7xd"
      },
      "source": [
        "def get_pad_mask(tokens, i_pad=0):\n",
        "    \"\"\"\n",
        "    pad mask 계산하는 함수\n",
        "    :param tokens: tokens (bs, n_seq)\n",
        "    :param i_pad: id of pad\n",
        "    :return mask: pad mask (pad: 1, other: 0)\n",
        "    \"\"\"\n",
        "    # 0인 부분 확인\n",
        "    mask = tf.math.equal(tokens, i_pad)\n",
        "    # boolean -> float 32\n",
        "    mask = tf.cast(mask, tf.float32)\n",
        "    # expand dimension for n_seq\n",
        "    mask = tf.expand_dims(mask, axis=1)\n",
        "    # print(mask)\n",
        "    return mask"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GqJIRPejHOuX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eeb84869-6a87-4431-a510-4eb149a81b3f"
      },
      "source": [
        "enc_pad_mask = get_pad_mask(train_enc_inputs)\n",
        "enc_pad_mask"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 1, 4), dtype=float32, numpy=array([[[0., 0., 0., 1.]]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AP6eq87QHWHv"
      },
      "source": [
        "## Causal Mask"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jgCB3zk-HykT"
      },
      "source": [
        "def get_causal_mask(tokens, i_pad=0):\n",
        "    \"\"\"\n",
        "    causal mask 계산하는 함수\n",
        "    :param tokens: tokens (bs, n_seq)\n",
        "    :param i_pad: id of pad\n",
        "    :return mask: causal and pad mask (causal or pad: 1, other: 0)\n",
        "    \"\"\"\n",
        "    # 개수 조회\n",
        "    n_seq = tf.shape(tokens)[1]\n",
        "    # make ahead mask\n",
        "    mask = 1 - tf.linalg.band_part(tf.ones((n_seq, n_seq)), -1, 0)\n",
        "    # expand dim for bs\n",
        "    mask = tf.expand_dims(mask, axis=0)\n",
        "    # get pad_mask\n",
        "    pad_mask = get_pad_mask(tokens, i_pad)\n",
        "    # mask all ahead_mask or pad_mask\n",
        "    mask = tf.maximum(mask, pad_mask)\n",
        "    return mask"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gUsByA_eH296",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d4069fe-9b92-4cdb-a024-bcc2e2255df8"
      },
      "source": [
        "dec_causal_mask = get_causal_mask(train_dec_inputs)\n",
        "dec_causal_mask"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 6, 6), dtype=float32, numpy=\n",
              "array([[[0., 1., 1., 1., 1., 1.],\n",
              "        [0., 0., 1., 1., 1., 1.],\n",
              "        [0., 0., 0., 1., 1., 1.],\n",
              "        [0., 0., 0., 0., 1., 1.],\n",
              "        [0., 0., 0., 0., 0., 1.],\n",
              "        [0., 0., 0., 0., 0., 1.]]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "itVetPQs1D98"
      },
      "source": [
        "## Mask 생성"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BRfuGqhx1Ddw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cbaa752d-27d7-4058-bc03-ea713915303a"
      },
      "source": [
        "# Encoder Self Attetnion mask\n",
        "enc_self_mask = get_pad_mask(train_enc_inputs)\n",
        "enc_self_mask"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 1, 4), dtype=float32, numpy=array([[[0., 0., 0., 1.]]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bGIvBeLy1C5P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ce70cb9-a61d-43d3-f317-69b7b0c93995"
      },
      "source": [
        "# Decoder Self Attetnion mask\n",
        "dec_self_mask = get_causal_mask(train_dec_inputs)\n",
        "dec_self_mask"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 6, 6), dtype=float32, numpy=\n",
              "array([[[0., 1., 1., 1., 1., 1.],\n",
              "        [0., 0., 1., 1., 1., 1.],\n",
              "        [0., 0., 0., 1., 1., 1.],\n",
              "        [0., 0., 0., 0., 1., 1.],\n",
              "        [0., 0., 0., 0., 0., 1.],\n",
              "        [0., 0., 0., 0., 0., 1.]]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MbU42aps1Vy3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ac647f6-105c-4f96-b751-23d878d2f887"
      },
      "source": [
        "# Encoder-Decoder Attetnion mask\n",
        "enc_dec_mask = get_pad_mask(train_enc_inputs)\n",
        "enc_dec_mask"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 1, 4), dtype=float32, numpy=array([[[0., 0., 0., 1.]]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A_kvndtnH-gh"
      },
      "source": [
        "# Scaled dot product attention"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IFkp9rLd_Etz"
      },
      "source": [
        "class ScaleDotProductAttention(tf.keras.layers.Layer):\n",
        "    \"\"\"\n",
        "    Scale Dot Product Attention Class\n",
        "    \"\"\"\n",
        "    def __init__(self, name=\"scale_dot_product_attention\"):\n",
        "        \"\"\"\n",
        "        생성자\n",
        "        :param name: layer name\n",
        "        \"\"\"\n",
        "        super().__init__(name=name)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        \"\"\"\n",
        "        layer 실행\n",
        "        :param inputs: Q, K, V, attn_mask tuple\n",
        "        :return attn_out: attention 실행 결과\n",
        "        \"\"\"\n",
        "        Q, K, V, attn_mask = inputs\n",
        "        # print(inputs)\n",
        "        # matmul Q, K (transpose_b=True)\n",
        "        attn_score = tf.matmul(Q, K, transpose_b=True)\n",
        "        # print(attn_score)\n",
        "        # get scale = d_model ** 0.5\n",
        "        scale = tf.math.sqrt(tf.cast(tf.shape(K)[-1], tf.float32))\n",
        "        # print(scale)\n",
        "        # divide by scale\n",
        "        attn_scale = tf.math.divide(attn_score, scale)\n",
        "        # print(attn_scale)\n",
        "        # do mask (subtract 1e-9 for masked value)\n",
        "        attn_scale -= 1.e9 * attn_mask\n",
        "        # print(attn_scale)\n",
        "        # calculate attention prob\n",
        "        attn_prob = tf.nn.softmax(attn_scale, axis=-1)\n",
        "        # print(attn_prob)\n",
        "        # weighted sum of V\n",
        "        attn_out = tf.matmul(attn_prob, V)\n",
        "        # print(attn_out)\n",
        "        return attn_out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QlFeIqeUAlOd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27d5c519-9ba2-4b3b-c19e-f0429241ca9a"
      },
      "source": [
        "# Encoder Self Attetnion\n",
        "Q = hidden_enc\n",
        "K = hidden_enc\n",
        "V = hidden_enc\n",
        "\n",
        "attention = ScaleDotProductAttention()\n",
        "attn_out = attention((Q, K, V, enc_self_mask))\n",
        "attn_out"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 4, 8), dtype=float32, numpy=\n",
              "array([[[-0.38933986,  0.07112095, -0.16520979,  0.20013933,\n",
              "          0.36103696,  0.25173742, -0.00415151, -0.50428855],\n",
              "        [-0.34047824,  0.44622278, -0.3593463 ,  0.0855836 ,\n",
              "          0.5193899 ,  0.26613465,  0.3384088 , -0.6653293 ],\n",
              "        [-0.17536503, -0.10861103, -0.38723904,  0.06453344,\n",
              "          0.3467061 ,  0.13054141, -0.25767758, -0.39562   ],\n",
              "        [-0.28988382,  0.19854634, -0.34112462,  0.09473331,\n",
              "          0.43631238,  0.21673402,  0.08101988, -0.547999  ]]],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pU-46iGWeIM3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d1fba6f-9aa4-49bd-c5c8-568d3dee4735"
      },
      "source": [
        "# Decoder Self Attetnion\n",
        "Q = hidden_dec\n",
        "K = hidden_dec\n",
        "V = hidden_dec\n",
        "\n",
        "attn_out = attention((Q, K, V, dec_self_mask))\n",
        "attn_out"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 6, 8), dtype=float32, numpy=\n",
              "array([[[-0.89      ,  0.52      , -0.87      , -0.6       ,\n",
              "          0.5       ,  0.19      , -0.71      , -0.64      ],\n",
              "        [-0.81045854, -0.17314747, -0.7961401 , -0.4238724 ,\n",
              "          0.34659854,  0.11614002, -0.10207558, -0.46387237],\n",
              "        [-0.56144136, -0.25976264,  0.28146774,  0.2427778 ,\n",
              "          0.11005872,  0.49197903,  0.43478104, -0.20985326],\n",
              "        [-0.5747526 , -0.30629176, -0.7071965 , -0.5053049 ,\n",
              "          0.41316307, -0.12226334, -0.2576017 , -0.22629057],\n",
              "        [-0.09017085, -0.32786977, -0.06507014, -0.5238511 ,\n",
              "          0.2422172 , -0.33344442, -0.24474701, -0.1312621 ],\n",
              "        [-0.43553102, -0.3018549 , -0.30060858, -0.3476541 ,\n",
              "          0.28297472, -0.0423666 , -0.08249234, -0.21670395]]],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uxxgRGhJfdAj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "979a4163-afb0-4dd8-9f1a-357171201cbd"
      },
      "source": [
        "# Encoder-Decoder Attetnion\n",
        "Q = hidden_dec\n",
        "K = hidden_enc\n",
        "V = hidden_enc\n",
        "\n",
        "attn_out = attention((Q, K, V, enc_dec_mask))\n",
        "attn_out"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 6, 8), dtype=float32, numpy=\n",
              "array([[[-0.26965153,  0.15192112, -0.35190547,  0.08786301,\n",
              "          0.4234491 ,  0.2022787 ,  0.02853429, -0.5244904 ],\n",
              "        [-0.28569198,  0.08716378, -0.30829674,  0.11374261,\n",
              "          0.39413947,  0.20345482, -0.02774149, -0.49769774],\n",
              "        [-0.43647614,  0.11320846, -0.11715899,  0.22951071,\n",
              "          0.36516273,  0.27868778,  0.05409794, -0.52934116],\n",
              "        [-0.16213647, -0.08165368, -0.41408706,  0.04850309,\n",
              "          0.36060563,  0.12689751, -0.2367178 , -0.40590388],\n",
              "        [-0.21452299, -0.07886577, -0.34552276,  0.08998163,\n",
              "          0.34810677,  0.15240252, -0.21430917, -0.41410154],\n",
              "        [-0.28988382,  0.19854634, -0.34112462,  0.09473331,\n",
              "          0.43631238,  0.21673402,  0.08101988, -0.547999  ]]],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y6_0vG8SISFB"
      },
      "source": [
        "# Multi Head Attention"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lwLM0dugG1Cl",
        "outputId": "d0c5d1d6-bc0f-461c-e82b-841b76d1af0e"
      },
      "source": [
        "args"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Namespace(d_ff=32, d_head=3, d_model=8, dropout=0.1, i_pad=0, n_head=2, n_layer=6, n_seq=6, n_vocab=11, norm_eps=1e-09, seed=1234)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3dkSuTsQXJTZ"
      },
      "source": [
        "class MultiHeadAttention(tf.keras.layers.Layer):\n",
        "    \"\"\"\n",
        "    Multi Head Attention Class\n",
        "    \"\"\"\n",
        "    def __init__(self, args, name=\"multi_head_attention\"):\n",
        "        \"\"\"\n",
        "        생성자\n",
        "        :param args: Args 객체\n",
        "        :param name: layer name\n",
        "        \"\"\"\n",
        "        super().__init__(name=name)\n",
        "\n",
        "        self.d_model = args.d_model\n",
        "        self.n_head = args.n_head\n",
        "        self.d_head = args.d_head\n",
        "\n",
        "        # Q, K, V input dense layer\n",
        "        self.W_Q = tf.keras.layers.Dense(self.n_head * self.d_head)  # n_head = h\n",
        "        self.W_K = tf.keras.layers.Dense(self.n_head * self.d_head)\n",
        "        self.W_V = tf.keras.layers.Dense(self.n_head * self.d_head)\n",
        "        # Scale Dot Product Attention class\n",
        "        self.attention = ScaleDotProductAttention(name=\"self_attention\")\n",
        "        # output dense layer\n",
        "        self.W_O = tf.keras.layers.Dense(self.d_model)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        \"\"\"\n",
        "        layer 실행\n",
        "        :param inputs: Q, K, V, attn_mask tuple\n",
        "        :return attn_out: attention 실행 결과\n",
        "        \"\"\"\n",
        "        Q, K, V, attn_mask = inputs\n",
        "        print(inputs)\n",
        "        # Q_m = self.W_Q(Q) # Q = (4,8) -> (4,6)\n",
        "        # print(Q_m) # ->이때 4 = 입력 길이 , 8 = d_model , 6 = h_head * d-head\n",
        "        # tf.reshape(Q_m, [-1, tf.shape(Q)[1], self.n_head, self.d_head]) # 쪼갰어 긴거를\n",
        "        # print(Q_m)\n",
        "        # Q_m = tf.transpose(Q_m, [0,2,1,3]) # 잘라진거를 \n",
        "        # print(Q_m)\n",
        "\n",
        "        # build multihead Q, K, V\n",
        "        Q_m = tf.transpose(tf.reshape(self.W_Q(Q), [-1, tf.shape(Q)[1], self.n_head, self.d_head]), [0, 2, 1, 3])  # (bs, Q_len, d_model) -> (bs, n_head, Q_len, d_head)\n",
        "        K_m = tf.transpose(tf.reshape(self.W_K(K), [-1, tf.shape(K)[1], self.n_head, self.d_head]), [0, 2, 1, 3])  # (bs, n_head, K_len, d_head)\n",
        "        V_m = tf.transpose(tf.reshape(self.W_V(V), [-1, tf.shape(V)[1], self.n_head, self.d_head]), [0, 2, 1, 3])  # (bs, n_head, K_len, d_head)\n",
        "        print(Q_m, K_m, V_m)\n",
        "        # # build multihead mask\n",
        "        attn_mask_m = tf.expand_dims(attn_mask, axis=1) # 연산 시키려면 차원 같게 해줘야 되니까 mask의 차원을 하나 늘려준거야-> 브로드 캐스팅하려고\n",
        "        print(attn_mask_m)\n",
        "        # Scale Dot Product Attention with multi head Q, K, V, attn_mask\n",
        "        attn_out_m = self.attention((Q_m, K_m, V_m, attn_mask_m))  # (bs, n_head, Q_len, d_head)\n",
        "        print(attn_out_m)\n",
        "        # transpose and reshape\n",
        "        attn_out_t = tf.transpose(attn_out_m, perm=[0, 2, 1, 3])  # (bs, Q_len, n_head, d_head)\n",
        "        print(attn_out_t)\n",
        "        attn_out_c = tf.reshape(attn_out_t, [-1, tf.shape(Q)[1], self.n_head * self.d_head])  # (bs, Q_len, d_model)\n",
        "        print(attn_out_c)\n",
        "        # linear for output\n",
        "        attn_out = self.W_O(attn_out_c) # (bs, Q_len, d_model)\n",
        "        # print(attn_out)\n",
        "        return attn_out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iYJFgcWCzjka",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0341b1c5-6dbd-40c4-83cc-e7850b819947"
      },
      "source": [
        "# Encoder Self Attetnion\n",
        "Q = hidden_enc\n",
        "K = hidden_enc\n",
        "V = hidden_enc\n",
        "\n",
        "attention = MultiHeadAttention(args)\n",
        "attn_out = attention((Q, K, V, enc_self_mask))\n",
        "attn_out"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(<tf.Tensor: shape=(1, 4, 8), dtype=float32, numpy=\n",
            "array([[[-0.75, -0.18,  0.4 ,  0.54,  0.17,  0.4 , -0.11, -0.44],\n",
            "        [-0.33,  0.93, -0.54, -0.02,  0.71,  0.31,  0.8 , -0.88],\n",
            "        [ 0.19, -0.55, -0.72, -0.14,  0.27, -0.09, -0.82, -0.15],\n",
            "        [-0.06,  0.15, -0.9 ,  0.31,  0.08,  0.  ,  0.71,  0.24]]],\n",
            "      dtype=float32)>, <tf.Tensor: shape=(1, 4, 8), dtype=float32, numpy=\n",
            "array([[[-0.75, -0.18,  0.4 ,  0.54,  0.17,  0.4 , -0.11, -0.44],\n",
            "        [-0.33,  0.93, -0.54, -0.02,  0.71,  0.31,  0.8 , -0.88],\n",
            "        [ 0.19, -0.55, -0.72, -0.14,  0.27, -0.09, -0.82, -0.15],\n",
            "        [-0.06,  0.15, -0.9 ,  0.31,  0.08,  0.  ,  0.71,  0.24]]],\n",
            "      dtype=float32)>, <tf.Tensor: shape=(1, 4, 8), dtype=float32, numpy=\n",
            "array([[[-0.75, -0.18,  0.4 ,  0.54,  0.17,  0.4 , -0.11, -0.44],\n",
            "        [-0.33,  0.93, -0.54, -0.02,  0.71,  0.31,  0.8 , -0.88],\n",
            "        [ 0.19, -0.55, -0.72, -0.14,  0.27, -0.09, -0.82, -0.15],\n",
            "        [-0.06,  0.15, -0.9 ,  0.31,  0.08,  0.  ,  0.71,  0.24]]],\n",
            "      dtype=float32)>, <tf.Tensor: shape=(1, 1, 4), dtype=float32, numpy=array([[[0., 0., 0., 1.]]], dtype=float32)>)\n",
            "tf.Tensor(\n",
            "[[[[ 0.31789923 -0.21676937 -0.1176548 ]\n",
            "   [-1.1124067   0.6707586  -0.0547175 ]\n",
            "   [ 0.64790964 -0.3607812  -0.17669818]\n",
            "   [-0.84277076  0.81534886 -0.00291975]]\n",
            "\n",
            "  [[ 0.22378805  0.02674545  0.49917978]\n",
            "   [ 0.64629096  0.68630177 -0.22349319]\n",
            "   [-0.08981233  0.00791439  0.10039341]\n",
            "   [ 1.1377947   0.450886   -0.37066966]]]], shape=(1, 2, 4, 3), dtype=float32) tf.Tensor(\n",
            "[[[[-0.43011662 -1.0042081  -0.7598613 ]\n",
            "   [-0.28681675 -0.6166858   0.39916962]\n",
            "   [-0.33171052  0.19675127 -0.42964903]\n",
            "   [ 0.66660416  0.6221609   0.5582949 ]]\n",
            "\n",
            "  [[-0.02391621 -0.4914031   0.46089655]\n",
            "   [-0.33521777  0.99995136  0.0220888 ]\n",
            "   [-0.10834113 -0.48526788  0.7802187 ]\n",
            "   [-0.04067114  0.6931677  -0.31677064]]]], shape=(1, 2, 4, 3), dtype=float32) tf.Tensor(\n",
            "[[[[ 0.27050284 -0.18967804 -0.9874222 ]\n",
            "   [ 0.18785524 -0.56579316 -1.465194  ]\n",
            "   [ 0.33365104 -0.24726562  0.6590781 ]\n",
            "   [-0.24366148 -0.2442733  -0.58846086]]\n",
            "\n",
            "  [[-0.5199902   0.24656421  0.19026786]\n",
            "   [ 0.79275405  0.86216223 -1.4009975 ]\n",
            "   [ 0.32545274 -0.07511238  0.14827909]\n",
            "   [ 0.55602384  0.23895708 -0.7458215 ]]]], shape=(1, 2, 4, 3), dtype=float32)\n",
            "tf.Tensor([[[[0. 0. 0. 1.]]]], shape=(1, 1, 1, 4), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[[[ 0.26303574 -0.33070862 -0.63292927]\n",
            "   [ 0.27306426 -0.32377347 -0.4311841 ]\n",
            "   [ 0.26213473 -0.32960188 -0.6574802 ]\n",
            "   [ 0.27407756 -0.32587582 -0.40038693]]\n",
            "\n",
            "  [[ 0.1761117   0.30903196 -0.2922709 ]\n",
            "   [ 0.31157508  0.45228386 -0.5655889 ]\n",
            "   [ 0.19988666  0.34089383 -0.3494373 ]\n",
            "   [ 0.25412625  0.41128308 -0.476708  ]]]], shape=(1, 2, 4, 3), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[[[ 0.26303574 -0.33070862 -0.63292927]\n",
            "   [ 0.1761117   0.30903196 -0.2922709 ]]\n",
            "\n",
            "  [[ 0.27306426 -0.32377347 -0.4311841 ]\n",
            "   [ 0.31157508  0.45228386 -0.5655889 ]]\n",
            "\n",
            "  [[ 0.26213473 -0.32960188 -0.6574802 ]\n",
            "   [ 0.19988666  0.34089383 -0.3494373 ]]\n",
            "\n",
            "  [[ 0.27407756 -0.32587582 -0.40038693]\n",
            "   [ 0.25412625  0.41128308 -0.476708  ]]]], shape=(1, 4, 2, 3), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[[ 0.26303574 -0.33070862 -0.63292927  0.1761117   0.30903196\n",
            "   -0.2922709 ]\n",
            "  [ 0.27306426 -0.32377347 -0.4311841   0.31157508  0.45228386\n",
            "   -0.5655889 ]\n",
            "  [ 0.26213473 -0.32960188 -0.6574802   0.19988666  0.34089383\n",
            "   -0.3494373 ]\n",
            "  [ 0.27407756 -0.32587582 -0.40038693  0.25412625  0.41128308\n",
            "   -0.476708  ]]], shape=(1, 4, 6), dtype=float32)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 4, 8), dtype=float32, numpy=\n",
              "array([[[-0.49435332, -0.2405638 , -0.25250086,  0.38179183,\n",
              "         -0.00297513, -0.05331107, -0.18338923,  0.37701666],\n",
              "        [-0.6845567 , -0.00480074, -0.04757795,  0.45028195,\n",
              "         -0.0696075 , -0.03893483, -0.17173499,  0.42125192],\n",
              "        [-0.549003  , -0.22678691, -0.23868808,  0.42498147,\n",
              "         -0.04111366, -0.02519875, -0.1796784 ,  0.39987102],\n",
              "        [-0.6031012 , -0.02820833, -0.07853937,  0.38559395,\n",
              "          0.00413214, -0.09124707, -0.16833101,  0.39549625]]],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wa63kI8kGXiL",
        "outputId": "d31e2fb9-11b2-4cfd-e175-9b0822d18cc0"
      },
      "source": [
        "# 디코더 마스크는 casual mask니까 다르지\n",
        "dec_self_mask"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 6, 6), dtype=float32, numpy=\n",
              "array([[[0., 1., 1., 1., 1., 1.],\n",
              "        [0., 0., 1., 1., 1., 1.],\n",
              "        [0., 0., 0., 1., 1., 1.],\n",
              "        [0., 0., 0., 0., 1., 1.],\n",
              "        [0., 0., 0., 0., 0., 1.],\n",
              "        [0., 0., 0., 0., 0., 1.]]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sD7ckaZWznSu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3995c019-c832-41b3-c74c-23f416c724e4"
      },
      "source": [
        "# Decoder Self Attetnion\n",
        "Q = hidden_dec\n",
        "K = hidden_dec\n",
        "V = hidden_dec\n",
        "\n",
        "attn_out = attention((Q, K, V, dec_self_mask)) # 마스크만 다른거지\n",
        "attn_out"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(<tf.Tensor: shape=(1, 6, 8), dtype=float32, numpy=\n",
            "array([[[-0.52,  0.46,  0.92,  0.55, -0.49, -0.43,  0.57,  0.81],\n",
            "        [ 0.88, -0.39,  0.87,  0.16, -0.86, -0.87,  0.37, -0.02],\n",
            "        [-0.44,  0.04,  0.85, -0.27, -0.06, -0.85,  0.34, -0.18],\n",
            "        [-0.18,  0.94, -0.76, -0.09, -0.3 ,  0.12, -0.82, -0.49],\n",
            "        [ 0.71, -0.21, -0.27,  0.19,  0.26, -0.73, -0.89, -0.89],\n",
            "        [-0.65, -0.69,  0.6 ,  0.83, -0.71, -0.49,  0.85,  0.74]]],\n",
            "      dtype=float32)>, <tf.Tensor: shape=(1, 6, 8), dtype=float32, numpy=\n",
            "array([[[-0.52,  0.46,  0.92,  0.55, -0.49, -0.43,  0.57,  0.81],\n",
            "        [ 0.88, -0.39,  0.87,  0.16, -0.86, -0.87,  0.37, -0.02],\n",
            "        [-0.44,  0.04,  0.85, -0.27, -0.06, -0.85,  0.34, -0.18],\n",
            "        [-0.18,  0.94, -0.76, -0.09, -0.3 ,  0.12, -0.82, -0.49],\n",
            "        [ 0.71, -0.21, -0.27,  0.19,  0.26, -0.73, -0.89, -0.89],\n",
            "        [-0.65, -0.69,  0.6 ,  0.83, -0.71, -0.49,  0.85,  0.74]]],\n",
            "      dtype=float32)>, <tf.Tensor: shape=(1, 6, 8), dtype=float32, numpy=\n",
            "array([[[-0.52,  0.46,  0.92,  0.55, -0.49, -0.43,  0.57,  0.81],\n",
            "        [ 0.88, -0.39,  0.87,  0.16, -0.86, -0.87,  0.37, -0.02],\n",
            "        [-0.44,  0.04,  0.85, -0.27, -0.06, -0.85,  0.34, -0.18],\n",
            "        [-0.18,  0.94, -0.76, -0.09, -0.3 ,  0.12, -0.82, -0.49],\n",
            "        [ 0.71, -0.21, -0.27,  0.19,  0.26, -0.73, -0.89, -0.89],\n",
            "        [-0.65, -0.69,  0.6 ,  0.83, -0.71, -0.49,  0.85,  0.74]]],\n",
            "      dtype=float32)>, <tf.Tensor: shape=(1, 6, 6), dtype=float32, numpy=\n",
            "array([[[0., 1., 1., 1., 1., 1.],\n",
            "        [0., 0., 1., 1., 1., 1.],\n",
            "        [0., 0., 0., 1., 1., 1.],\n",
            "        [0., 0., 0., 0., 1., 1.],\n",
            "        [0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 1.]]], dtype=float32)>)\n",
            "tf.Tensor(\n",
            "[[[[-0.2396463  -0.34698662 -0.3645139  -0.37896267]\n",
            "   [ 0.5972051  -0.6392531   0.10456431  0.12222138]\n",
            "   [-0.38374215  0.23059143 -0.2207563  -0.40186363]\n",
            "   [-1.0650139   0.3506698   0.23226261  0.31263486]\n",
            "   [-0.63988847 -0.24629599  0.47192633  1.0362339 ]\n",
            "   [ 0.3248932  -0.31515542  0.29639617 -0.75601614]]\n",
            "\n",
            "  [[ 0.01863512  0.06023493  0.9424754  -0.07773357]\n",
            "   [-0.72447264  0.26689342  0.30505303  0.82729214]\n",
            "   [-0.16981138  0.47024268 -0.20462783  0.9683117 ]\n",
            "   [ 0.04112274 -0.26188645  0.47568715 -0.07188608]\n",
            "   [-0.4200683   0.09549499 -0.48706564  0.96262723]\n",
            "   [ 0.0862622  -0.01156069  0.20995963  0.16038515]]]], shape=(1, 2, 6, 4), dtype=float32) tf.Tensor(\n",
            "[[[[ 0.62957835 -0.6543945   0.3838658   0.82262367]\n",
            "   [-0.7657039   0.294895   -0.1798369   0.84853584]\n",
            "   [ 0.14964259 -0.17501463 -0.88895744 -0.3596034 ]\n",
            "   [ 0.41547924 -0.15169123  0.787143    0.2727715 ]\n",
            "   [-0.48456407  0.38342792 -0.41479027  0.17707244]\n",
            "   [-0.35200742 -0.17721403  0.06035795  0.6932356 ]]\n",
            "\n",
            "  [[-0.42275748  1.8964707   0.33008322 -1.209263  ]\n",
            "   [-0.60284626  0.6221367   0.21757637 -1.412211  ]\n",
            "   [-0.49604353  1.1838567  -0.02887204 -0.7048164 ]\n",
            "   [ 0.64635867 -0.5994573  -1.2144394   1.2388648 ]\n",
            "   [ 0.297281   -0.72720027 -0.08471094  0.2690829 ]\n",
            "   [-0.5518093   1.6763582   0.7903708  -1.876954  ]]]], shape=(1, 2, 6, 4), dtype=float32) tf.Tensor(\n",
            "[[[[-0.7382732  -0.3373922   0.9321632   0.41229188]\n",
            "   [-0.0267053   0.918217    0.53528947  0.5563245 ]\n",
            "   [-0.40110976  0.1845042   0.7196021  -0.25280076]\n",
            "   [-0.36639455 -0.74323493 -0.55512935 -0.18996295]\n",
            "   [-0.28991732  1.4263777  -0.23547821 -0.60383254]\n",
            "   [-0.20232216  0.12770788  1.3185397   0.4020597 ]]\n",
            "\n",
            "  [[ 0.07838749 -0.23430431 -0.35105315 -0.44473788]\n",
            "   [-0.3422498   0.10807385 -0.9586853  -0.500493  ]\n",
            "   [-0.06519376  0.4893263   0.15028639  0.37568513]\n",
            "   [ 0.28502145  0.5939838   0.2624646   0.7611434 ]\n",
            "   [-0.4825541   0.72879416 -0.32931036  0.48047912]\n",
            "   [-0.47390133 -1.1863271  -0.92565215 -1.282465  ]]]], shape=(1, 2, 6, 4), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[[[0. 1. 1. 1. 1. 1.]\n",
            "   [0. 0. 1. 1. 1. 1.]\n",
            "   [0. 0. 0. 1. 1. 1.]\n",
            "   [0. 0. 0. 0. 1. 1.]\n",
            "   [0. 0. 0. 0. 0. 1.]\n",
            "   [0. 0. 0. 0. 0. 1.]]]], shape=(1, 1, 6, 6), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[[[-0.7382732  -0.3373922   0.9321632   0.41229188]\n",
            "   [-0.5096677   0.06599749  0.80465955  0.45856526]\n",
            "   [-0.3442474   0.32872063  0.7026094   0.199198  ]\n",
            "   [-0.29639283  0.20250201  0.40827286  0.22343196]\n",
            "   [-0.34550732  0.31054956  0.29918218  0.08911593]\n",
            "   [-0.3954238   0.15322866  0.26129457 -0.04829203]]\n",
            "\n",
            "  [[ 0.07838749 -0.23430431 -0.35105315 -0.44473788]\n",
            "   [-0.11035192 -0.08067967 -0.6236969  -0.4697551 ]\n",
            "   [-0.08208519  0.13907173 -0.2993009  -0.13015166]\n",
            "   [-0.03091924  0.22466488 -0.26557496  0.00815495]\n",
            "   [-0.02286009  0.45211768 -0.08405537  0.35820052]\n",
            "   [-0.10590114  0.35312238 -0.23351394  0.15855095]]]], shape=(1, 2, 6, 4), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[[[-0.7382732  -0.3373922   0.9321632   0.41229188]\n",
            "   [ 0.07838749 -0.23430431 -0.35105315 -0.44473788]]\n",
            "\n",
            "  [[-0.5096677   0.06599749  0.80465955  0.45856526]\n",
            "   [-0.11035192 -0.08067967 -0.6236969  -0.4697551 ]]\n",
            "\n",
            "  [[-0.3442474   0.32872063  0.7026094   0.199198  ]\n",
            "   [-0.08208519  0.13907173 -0.2993009  -0.13015166]]\n",
            "\n",
            "  [[-0.29639283  0.20250201  0.40827286  0.22343196]\n",
            "   [-0.03091924  0.22466488 -0.26557496  0.00815495]]\n",
            "\n",
            "  [[-0.34550732  0.31054956  0.29918218  0.08911593]\n",
            "   [-0.02286009  0.45211768 -0.08405537  0.35820052]]\n",
            "\n",
            "  [[-0.3954238   0.15322866  0.26129457 -0.04829203]\n",
            "   [-0.10590114  0.35312238 -0.23351394  0.15855095]]]], shape=(1, 6, 2, 4), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[[-0.7382732  -0.3373922   0.9321632   0.41229188  0.07838749\n",
            "   -0.23430431 -0.35105315 -0.44473788]\n",
            "  [-0.5096677   0.06599749  0.80465955  0.45856526 -0.11035192\n",
            "   -0.08067967 -0.6236969  -0.4697551 ]\n",
            "  [-0.3442474   0.32872063  0.7026094   0.199198   -0.08208519\n",
            "    0.13907173 -0.2993009  -0.13015166]\n",
            "  [-0.29639283  0.20250201  0.40827286  0.22343196 -0.03091924\n",
            "    0.22466488 -0.26557496  0.00815495]\n",
            "  [-0.34550732  0.31054956  0.29918218  0.08911593 -0.02286009\n",
            "    0.45211768 -0.08405537  0.35820052]\n",
            "  [-0.3954238   0.15322866  0.26129457 -0.04829203 -0.10590114\n",
            "    0.35312238 -0.23351394  0.15855095]]], shape=(1, 6, 8), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[[ 0.3555967   0.84587234 -0.5819368   0.608038   -0.48327428\n",
            "    0.72860336  0.843408   -0.9726673 ]\n",
            "  [ 0.53374755  0.59809047 -0.4258754   0.8302195   0.07406984\n",
            "    0.81429887  0.74632967 -0.8283743 ]\n",
            "  [ 0.5418025   0.34537497 -0.37121993  0.7242239  -0.01845851\n",
            "    0.6664892   0.3942424  -0.5989568 ]\n",
            "  [ 0.45879188  0.2093037  -0.19352312  0.59346694  0.05096138\n",
            "    0.46890667  0.32418528 -0.45308948]\n",
            "  [ 0.5709845   0.05714472 -0.1661846   0.6452949  -0.04006106\n",
            "    0.42619225  0.1989047  -0.43701547]\n",
            "  [ 0.43654075  0.17306103 -0.19427249  0.5537096   0.01121719\n",
            "    0.54135317  0.38753048 -0.42183635]]], shape=(1, 6, 8), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vM9SlWCTzuI0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "232bea04-cf62-4acc-f1a2-d82ff81de334"
      },
      "source": [
        "# Encoder-Decoder Attetnion\n",
        "Q = hidden_dec\n",
        "K = hidden_enc\n",
        "V = hidden_enc\n",
        "\n",
        "attn_out = attention((Q, K, V, enc_dec_mask)) # k에다 마스크 거니까 shape이 같겟지\n",
        "attn_out"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(<tf.Tensor: shape=(1, 6, 8), dtype=float32, numpy=\n",
            "array([[[-0.89,  0.52, -0.87, -0.6 ,  0.5 ,  0.19, -0.71, -0.64],\n",
            "        [-0.75, -0.7 , -0.74, -0.29,  0.23,  0.06,  0.36, -0.33],\n",
            "        [-0.41, -0.28,  0.95,  0.65, -0.03,  0.73,  0.74, -0.06],\n",
            "        [-0.29, -0.62, -0.89, -0.79,  0.55, -0.6 , -0.52,  0.08],\n",
            "        [ 0.63, -0.34,  0.62, -0.78,  0.06, -0.82, -0.43, -0.03],\n",
            "        [-0.06,  0.15, -0.9 ,  0.31,  0.08,  0.  ,  0.71,  0.24]]],\n",
            "      dtype=float32)>, <tf.Tensor: shape=(1, 4, 8), dtype=float32, numpy=\n",
            "array([[[-0.75, -0.18,  0.4 ,  0.54,  0.17,  0.4 , -0.11, -0.44],\n",
            "        [-0.33,  0.93, -0.54, -0.02,  0.71,  0.31,  0.8 , -0.88],\n",
            "        [ 0.19, -0.55, -0.72, -0.14,  0.27, -0.09, -0.82, -0.15],\n",
            "        [-0.06,  0.15, -0.9 ,  0.31,  0.08,  0.  ,  0.71,  0.24]]],\n",
            "      dtype=float32)>, <tf.Tensor: shape=(1, 4, 8), dtype=float32, numpy=\n",
            "array([[[-0.75, -0.18,  0.4 ,  0.54,  0.17,  0.4 , -0.11, -0.44],\n",
            "        [-0.33,  0.93, -0.54, -0.02,  0.71,  0.31,  0.8 , -0.88],\n",
            "        [ 0.19, -0.55, -0.72, -0.14,  0.27, -0.09, -0.82, -0.15],\n",
            "        [-0.06,  0.15, -0.9 ,  0.31,  0.08,  0.  ,  0.71,  0.24]]],\n",
            "      dtype=float32)>, <tf.Tensor: shape=(1, 1, 4), dtype=float32, numpy=array([[[0., 0., 0., 1.]]], dtype=float32)>)\n",
            "tf.Tensor(\n",
            "[[[[-4.3529525e-01  2.1557924e-01 -1.5368998e-02]\n",
            "   [-3.5506994e-01  1.0466146e+00 -8.8371456e-01]\n",
            "   [ 4.5794386e-01 -6.0181218e-01 -4.4646251e-01]\n",
            "   [-6.4035827e-01  1.4632703e+00 -6.3566768e-01]\n",
            "   [-8.4452200e-01  4.6369877e-01  7.9418439e-01]\n",
            "   [ 3.8604525e-01  3.7826735e-01 -4.9869543e-01]]\n",
            "\n",
            "  [[ 9.3929899e-01 -3.7455836e-01  8.6804122e-01]\n",
            "   [ 3.4030962e-01 -1.7915824e-01  2.0573184e-01]\n",
            "   [-1.2501800e+00  2.6695794e-01 -8.7167144e-01]\n",
            "   [ 9.8336184e-01 -2.3465349e-01  7.1660352e-01]\n",
            "   [ 4.6788758e-01 -5.4216623e-01 -1.8160300e-01]\n",
            "   [-2.2231242e-01  6.7782080e-01  7.3682517e-04]]]], shape=(1, 2, 6, 3), dtype=float32) tf.Tensor(\n",
            "[[[[-0.6057857  -0.9809774   0.3686177 ]\n",
            "   [-1.5542793  -0.3554508   0.5608312 ]\n",
            "   [ 0.06594129  0.68567854  0.61839586]\n",
            "   [-0.29274267  0.3527158   0.09453534]]\n",
            "\n",
            "  [[ 0.3990579   0.6681184  -0.17822379]\n",
            "   [-0.37098765  1.3173707   0.16534889]\n",
            "   [ 0.9298229   0.00745139  0.3192089 ]\n",
            "   [-0.14496017  0.84099764  1.0237191 ]]]], shape=(1, 2, 4, 3), dtype=float32) tf.Tensor(\n",
            "[[[[ 0.24396582  1.0090411  -0.34451264]\n",
            "   [ 1.5526323  -0.2942712  -0.4480816 ]\n",
            "   [ 0.46191785  0.02120938 -0.5603069 ]\n",
            "   [ 0.04538161 -0.69965243  0.37905726]]\n",
            "\n",
            "  [[ 0.43970296 -0.19010884 -0.37273037]\n",
            "   [ 0.9120277  -0.52663416  0.66995966]\n",
            "   [-0.04659467 -0.34273243  0.7572637 ]\n",
            "   [ 0.08604088 -0.8700992   0.5184968 ]]]], shape=(1, 2, 4, 3), dtype=float32)\n",
            "tf.Tensor([[[[0. 0. 0. 1.]]]], shape=(1, 1, 1, 4), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[[[ 0.8364457   0.18434376 -0.45184404]\n",
            "   [ 0.7879844   0.12336802 -0.47614786]\n",
            "   [ 0.6562135   0.3809282  -0.43317813]\n",
            "   [ 0.82433105  0.0666515  -0.4843099 ]\n",
            "   [ 0.92991674  0.10025879 -0.45692214]\n",
            "   [ 0.6773477   0.22824465 -0.46875915]]\n",
            "\n",
            "  [[ 0.26488066 -0.33518147  0.4317508 ]\n",
            "   [ 0.36944777 -0.343167    0.36891872]\n",
            "   [ 0.6114513  -0.38965118  0.34713623]\n",
            "   [ 0.2792923  -0.33494556  0.41719052]\n",
            "   [ 0.321458   -0.33099926  0.36021468]\n",
            "   [ 0.541921   -0.3774381   0.35843796]]]], shape=(1, 2, 6, 3), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[[[ 0.8364457   0.18434376 -0.45184404]\n",
            "   [ 0.26488066 -0.33518147  0.4317508 ]]\n",
            "\n",
            "  [[ 0.7879844   0.12336802 -0.47614786]\n",
            "   [ 0.36944777 -0.343167    0.36891872]]\n",
            "\n",
            "  [[ 0.6562135   0.3809282  -0.43317813]\n",
            "   [ 0.6114513  -0.38965118  0.34713623]]\n",
            "\n",
            "  [[ 0.82433105  0.0666515  -0.4843099 ]\n",
            "   [ 0.2792923  -0.33494556  0.41719052]]\n",
            "\n",
            "  [[ 0.92991674  0.10025879 -0.45692214]\n",
            "   [ 0.321458   -0.33099926  0.36021468]]\n",
            "\n",
            "  [[ 0.6773477   0.22824465 -0.46875915]\n",
            "   [ 0.541921   -0.3774381   0.35843796]]]], shape=(1, 6, 2, 3), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[[ 0.8364457   0.18434376 -0.45184404  0.26488066 -0.33518147\n",
            "    0.4317508 ]\n",
            "  [ 0.7879844   0.12336802 -0.47614786  0.36944777 -0.343167\n",
            "    0.36891872]\n",
            "  [ 0.6562135   0.3809282  -0.43317813  0.6114513  -0.38965118\n",
            "    0.34713623]\n",
            "  [ 0.82433105  0.0666515  -0.4843099   0.2792923  -0.33494556\n",
            "    0.41719052]\n",
            "  [ 0.92991674  0.10025879 -0.45692214  0.321458   -0.33099926\n",
            "    0.36021468]\n",
            "  [ 0.6773477   0.22824465 -0.46875915  0.541921   -0.3774381\n",
            "    0.35843796]]], shape=(1, 6, 6), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[[ 0.0057458  -0.07197976  0.19949746  0.3140798  -0.54679453\n",
            "   -0.04018269  0.06678128 -0.16540217]\n",
            "  [-0.06511003 -0.13667825  0.1938524   0.308598   -0.46690863\n",
            "   -0.01933703  0.1080815  -0.19567624]\n",
            "  [ 0.10417655 -0.3957622  -0.11286414  0.44476885 -0.40291405\n",
            "   -0.11427679  0.02880159 -0.09948123]\n",
            "  [-0.08045582 -0.0724909   0.26360622  0.25186676 -0.5051072\n",
            "    0.01705298  0.10085115 -0.20881832]\n",
            "  [-0.09662917 -0.00626382  0.28880197  0.3800825  -0.5149604\n",
            "   -0.03497328  0.19567598 -0.25757968]\n",
            "  [ 0.00628841 -0.32836568  0.0131796   0.34843644 -0.39759055\n",
            "   -0.04176678  0.05967143 -0.14906824]]], shape=(1, 6, 8), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O0SdFzKfiQTH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}